{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting text from a PDF file"
      ],
      "metadata": {
        "id": "tqLTRCv0ArWH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_lLPmKHKsGH",
        "outputId": "c93108a0-b5fc-4d70-f5d7-3903c3c743fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 26.4 MB/s \n",
            "\u001b[?25hCollecting cryptography>=36.0.0\n",
            "  Downloading cryptography-38.0.3-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 71.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from pdfminer.six) (2.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pdfminer.six) (4.1.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
            "Installing collected packages: cryptography, pdfminer.six\n",
            "Successfully installed cryptography-38.0.3 pdfminer.six-20221105\n"
          ]
        }
      ],
      "source": [
        "!pip install pdfminer.six"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pdfminer.high_level import extract_text\n",
        " \n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    return extract_text(pdf_path)\n",
        " \n",
        "txt = extract_text_from_pdf(\"/content/Shraddha-Surywanshi-Resume-Final.pdf\")\n",
        "txt"
      ],
      "metadata": {
        "id": "UDwWB0TTLGpG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "74fca848-71bb-4859-cd0b-053198be1fe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'                   SHRADDHA SURYAWANSHI \\n\\nshraddha3m@gmail.com     8378032152 \\n\\nGithub \\n\\n           LinkedIn   \\n\\nEDUCATION  \\n\\nSYMBIOSIS INSTITUTE OF TECHNOLOGY   \\n\\nB.TECH in Information Technology  \\n (CGPA: 8.363/10.0)  \\n\\nPROJECTS  \\n\\nNGO EVENT MANAGEMENT WEBSITE,  \\nCo-developer  \\n\\nPune, MH, IN  \\n\\n2019-2023  \\n\\nApril, 2020   \\n\\n•  A website where an NGO can better reach donors by advertising their clothes/books donation drives.   \\n\\n•  Makes it convenient for donors by allowing them to request door step pickup to the NGO.  \\n\\n•  Uses JSP, Servlets, MySQL, HTML, CSS, JS.  \\n\\nDATA VISUALISATION WEBSITE Co-developer  \\n\\nOngoing  \\n\\nOctober 2021-   \\n\\n•  Helps an NGO to view their kitchen operations (material used and bought per month) efficiency visually in the \\n\\nform of simple charts.  \\n\\n•  Can help analyse and adjust raw materials usage and thereby reduce wastage.  \\n\\n•  Uses React, Bootstrap, node.js, MySQL.  \\n\\nETCH-A-SKETCH  \\nDeveloper  \\n\\n•  A sketch-pad like software of <=100*100 grid to practice DOM manipulation using JavaScript.  \\n\\n•  Grid cells change to desired colour when hovered over them.   \\n•  Uses JavaScript, HTML, CSS.  \\n\\nSKILLS AND RELEVANT COURSEWORK  \\n\\n  \\n  \\n \\n  \\n  \\n  \\n \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n \\n  \\n  \\n                      \\n                              \\n         \\n\\x0cJava, JSP, Servlets, MySQL, Python, C++, HTML, CSS, JS, React.  \\n\\n• \\n•  OS, Networking, Data structures, Agile software development, DBMS.  \\n\\nCERTIFICATIONS  \\n\\n• \\n\\n• \\n\\n• \\n\\n• \\n\\n• \\n\\nJava-in-depth, Udemy  \\n\\nSoftware development agile practices, Coursera.  \\nPython for Everybody, Coursera.  \\nCS50x, Harvard.  \\nReact-the complete guide, Udemy (ongoing).  \\n\\n  \\n \\n  \\n\\x0c'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting text from a word document"
      ],
      "metadata": {
        "id": "PtdCMEonA9fj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install docx2txt\n",
        "import docx2txt"
      ],
      "metadata": {
        "id": "LEuGswPUL31y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3d51f7c-db92-401b-952b-0f3f036dc013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting docx2txt\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "Building wheels for collected packages: docx2txt\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3981 sha256=c1fd937350784a6e55a3ba2c4e59cfeac31fbbc0d7b8908fe4305f3a0f15f853\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/20/b2/473e3aea9a0c0d3e7b2f7bd81d06d0794fec12752733d1f3a8\n",
            "Successfully built docx2txt\n",
            "Installing collected packages: docx2txt\n",
            "Successfully installed docx2txt-0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def doctotext(m):\n",
        "    temp = docx2txt.process(m)\n",
        "    resume_text = [line.replace('\\t', ' ') for line in temp.split('\\n') if line]\n",
        "    text = ' '.join(resume_text)\n",
        "    return (text)\n",
        "\n",
        "txt = doctotext('/content/sample_data/Shraddha-Surywanshi-Resume-Final.docx')\n",
        "txt"
      ],
      "metadata": {
        "id": "l_uNPeFjLznN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "dcc5771e-bb3a-470b-ac57-15981dd6c274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'SHRADDHA SURYAWANSHI                               shraddha3m@gmail.com     8378032152          Github           LinkedIn                                                SHRADDHA SURYAWANSHI                               shraddha3m@gmail.com     8378032152          Github           LinkedIn      EDUCATION      SYMBIOSIS INSTITUTE OF TECHNOLOGY   Pune, MH, IN  B.TECH in Information Technology    (CGPA: 8.363/10.0)  2019-2023    PROJECTS     NGO EVENT MANAGEMENT WEBSITE,  April, 2020   Co-developer  A website where an NGO can better reach donors by advertising their clothes/books donation drives.   Makes it convenient for donors by allowing them to request door step pickup to the NGO.  Uses JSP, Servlets, MySQL, HTML, CSS, JS.    DATA VISUALISATION WEBSITE Co-developer  Ongoing  October 2021-   Helps an NGO to view their kitchen operations (material used and bought per month) efficiency visually in the form of simple charts.  Can help analyse and adjust raw materials usage and thereby reduce wastage.  Uses React, Bootstrap, node.js, MySQL.     ETCH-A-SKETCH    Developer  A sketch-pad like software of <=100*100 grid to practice DOM manipulation using JavaScript.  Grid cells change to desired colour when hovered over them.   Uses JavaScript, HTML, CSS.        SKILLS AND RELEVANT COURSEWORK  Java, JSP, Servlets, MySQL, Python, C++, HTML, CSS, JS, React.  OS, Networking, Data structures, Agile software development, DBMS.    CERTIFICATIONS    Java-in-depth, Udemy  Software development agile practices, Coursera.  Python for Everybody, Coursera.  CS50x, Harvard.  React-the complete guide, Udemy (ongoing).'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting names using NLTK"
      ],
      "metadata": {
        "id": "4prU_6DaG7WY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "!pip install numpy # (also required by nltk, for running the following code)"
      ],
      "metadata": {
        "id": "CUkjqBMGM73s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7224a9b8-43ca-42eb-fdd0-62b0ca02ade6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import nltk\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "id": "Z6aXnWUKM-QC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a913c34c-26b5-45c6-b9a8-5ef8846bd4ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_names(txt):\n",
        "    person_names = []\n",
        " \n",
        "    for sent in nltk.sent_tokenize(txt):\n",
        "        for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))): #chunking tokens\n",
        "            if hasattr(chunk, 'label') and chunk.label() == 'PERSON':\n",
        "                person_names.append(\n",
        "                    ' '.join(chunk_leave[0] for chunk_leave in chunk.leaves()) #tree to tokens\n",
        "                )\n",
        "    \n",
        "    return person_names\n",
        " \n",
        "\n",
        "person_names = extract_names(txt)\n",
        "person_names"
      ],
      "metadata": {
        "id": "mY_kuzFpGfKi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bf4b327-fa8e-473e-849e-27ec90f691d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Github LinkedIn SHRADDHA',\n",
              " 'Github LinkedIn',\n",
              " 'React',\n",
              " 'Bootstrap',\n",
              " 'Python',\n",
              " 'React',\n",
              " 'Agile',\n",
              " 'Udemy Software',\n",
              " 'Harvard']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy"
      ],
      "metadata": {
        "id": "_OQKYJL2Ou1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38439a6e-0a50-49e2-fb4d-ba433b4230c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.4.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.10.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.1.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.3)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.10.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting names using spacy"
      ],
      "metadata": {
        "id": "xOYDJp6JLgLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.matcher import Matcher\n",
        "\n",
        "def extract_name(text):\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    nlp_text = nlp(text)\n",
        "\n",
        "    matcher = Matcher(nlp.vocab)\n",
        "    \n",
        "    # first, last name = Proper Nouns\n",
        "    pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
        "    \n",
        "    matcher.add('NAME', [pattern])\n",
        "    \n",
        "    matches = matcher(nlp_text)\n",
        "    \n",
        "    for match_id, start, end in matches:\n",
        "        span = nlp_text[start:end]\n",
        "        return span.text\n",
        "print('Name: ',extract_name(txt))"
      ],
      "metadata": {
        "id": "X7_OZXKPXHCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f404425d-52dd-48eb-a5fb-48e5af6b1499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name:  SHRADDHA SURYAWANSHI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tag.stanford import StanfordNERTagger\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "\n",
        "!wget 'https://nlp.stanford.edu/software/stanford-ner-2018-10-16.zip'\n",
        "!unzip stanford-ner-2018-10-16.zip\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n"
      ],
      "metadata": {
        "id": "KMc58qBJOzcM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72771fd5-a406-4c49-807d-d7ab32476597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-13 18:00:54--  https://nlp.stanford.edu/software/stanford-ner-2018-10-16.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://downloads.cs.stanford.edu/nlp/software/stanford-ner-2018-10-16.zip [following]\n",
            "--2022-11-13 18:00:54--  https://downloads.cs.stanford.edu/nlp/software/stanford-ner-2018-10-16.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 180358328 (172M) [application/zip]\n",
            "Saving to: ‘stanford-ner-2018-10-16.zip’\n",
            "\n",
            "stanford-ner-2018-1 100%[===================>] 172.00M  5.09MB/s    in 30s     \n",
            "\n",
            "2022-11-13 18:01:25 (5.72 MB/s) - ‘stanford-ner-2018-10-16.zip’ saved [180358328/180358328]\n",
            "\n",
            "Archive:  stanford-ner-2018-10-16.zip\n",
            "   creating: stanford-ner-2018-10-16/\n",
            "  inflating: stanford-ner-2018-10-16/README.txt  \n",
            "  inflating: stanford-ner-2018-10-16/ner-gui.bat  \n",
            "  inflating: stanford-ner-2018-10-16/build.xml  \n",
            "  inflating: stanford-ner-2018-10-16/stanford-ner.jar  \n",
            "  inflating: stanford-ner-2018-10-16/sample-conll-file.txt  \n",
            "  inflating: stanford-ner-2018-10-16/sample.ner.txt  \n",
            "  inflating: stanford-ner-2018-10-16/stanford-ner-3.9.2-sources.jar  \n",
            "   creating: stanford-ner-2018-10-16/lib/\n",
            "  inflating: stanford-ner-2018-10-16/lib/joda-time.jar  \n",
            "  inflating: stanford-ner-2018-10-16/lib/stanford-ner-resources.jar  \n",
            "  inflating: stanford-ner-2018-10-16/lib/jollyday-0.4.9.jar  \n",
            "  inflating: stanford-ner-2018-10-16/ner-gui.command  \n",
            "  inflating: stanford-ner-2018-10-16/ner.sh  \n",
            "  inflating: stanford-ner-2018-10-16/stanford-ner-3.9.2.jar  \n",
            "  inflating: stanford-ner-2018-10-16/NERDemo.java  \n",
            "  inflating: stanford-ner-2018-10-16/stanford-ner-3.9.2-javadoc.jar  \n",
            "  inflating: stanford-ner-2018-10-16/ner.bat  \n",
            "   creating: stanford-ner-2018-10-16/classifiers/\n",
            "  inflating: stanford-ner-2018-10-16/classifiers/english.conll.4class.distsim.prop  \n",
            "  inflating: stanford-ner-2018-10-16/classifiers/example.serialized.ncc.ncc.ser.gz  \n",
            "  inflating: stanford-ner-2018-10-16/classifiers/english.muc.7class.distsim.crf.ser.gz  \n",
            "  inflating: stanford-ner-2018-10-16/classifiers/english.conll.4class.distsim.crf.ser.gz  \n",
            "  inflating: stanford-ner-2018-10-16/classifiers/english.muc.7class.distsim.prop  \n",
            "  inflating: stanford-ner-2018-10-16/classifiers/english.all.3class.distsim.prop  \n",
            "  inflating: stanford-ner-2018-10-16/classifiers/example.serialized.ncc.prop  \n",
            "  inflating: stanford-ner-2018-10-16/classifiers/english.all.3class.distsim.crf.ser.gz  \n",
            "  inflating: stanford-ner-2018-10-16/sample.txt  \n",
            "  inflating: stanford-ner-2018-10-16/sample-w-time.txt  \n",
            "  inflating: stanford-ner-2018-10-16/ner-gui.sh  \n",
            "  inflating: stanford-ner-2018-10-16/LICENSE.txt  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "st = StanfordNERTagger('/content/stanford-ner-2018-10-16/classifiers/english.all.3class.distsim.crf.ser.gz',\n",
        "                       '/content/stanford-ner-2018-10-16/stanford-ner.jar',\n",
        "                       encoding='utf-8')\n",
        "\n",
        "\n",
        "tokenized_text = word_tokenize(txt)\n",
        "classified_text = st.tag(tokenized_text)\n",
        "print(tokenized_text)\n",
        "print(classified_text)"
      ],
      "metadata": {
        "id": "DrUua2qTPO-8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43dc1154-0775-4cf3-d316-57979c11cb2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['SHRADDHA', 'SURYAWANSHI', 'shraddha3m', '@', 'gmail.com', '8378032152', 'Github', 'LinkedIn', 'SHRADDHA', 'SURYAWANSHI', 'shraddha3m', '@', 'gmail.com', '8378032152', 'Github', 'LinkedIn', 'EDUCATION', 'SYMBIOSIS', 'INSTITUTE', 'OF', 'TECHNOLOGY', 'Pune', ',', 'MH', ',', 'IN', 'B.TECH', 'in', 'Information', 'Technology', '(', 'CGPA', ':', '8.363/10.0', ')', '2019-2023', 'PROJECTS', 'NGO', 'EVENT', 'MANAGEMENT', 'WEBSITE', ',', 'April', ',', '2020', 'Co-developer', 'A', 'website', 'where', 'an', 'NGO', 'can', 'better', 'reach', 'donors', 'by', 'advertising', 'their', 'clothes/books', 'donation', 'drives', '.', 'Makes', 'it', 'convenient', 'for', 'donors', 'by', 'allowing', 'them', 'to', 'request', 'door', 'step', 'pickup', 'to', 'the', 'NGO', '.', 'Uses', 'JSP', ',', 'Servlets', ',', 'MySQL', ',', 'HTML', ',', 'CSS', ',', 'JS', '.', 'DATA', 'VISUALISATION', 'WEBSITE', 'Co-developer', 'Ongoing', 'October', '2021-', 'Helps', 'an', 'NGO', 'to', 'view', 'their', 'kitchen', 'operations', '(', 'material', 'used', 'and', 'bought', 'per', 'month', ')', 'efficiency', 'visually', 'in', 'the', 'form', 'of', 'simple', 'charts', '.', 'Can', 'help', 'analyse', 'and', 'adjust', 'raw', 'materials', 'usage', 'and', 'thereby', 'reduce', 'wastage', '.', 'Uses', 'React', ',', 'Bootstrap', ',', 'node.js', ',', 'MySQL', '.', 'ETCH-A-SKETCH', 'Developer', 'A', 'sketch-pad', 'like', 'software', 'of', '<', '=100', '*', '100', 'grid', 'to', 'practice', 'DOM', 'manipulation', 'using', 'JavaScript', '.', 'Grid', 'cells', 'change', 'to', 'desired', 'colour', 'when', 'hovered', 'over', 'them', '.', 'Uses', 'JavaScript', ',', 'HTML', ',', 'CSS', '.', 'SKILLS', 'AND', 'RELEVANT', 'COURSEWORK', 'Java', ',', 'JSP', ',', 'Servlets', ',', 'MySQL', ',', 'Python', ',', 'C++', ',', 'HTML', ',', 'CSS', ',', 'JS', ',', 'React', '.', 'OS', ',', 'Networking', ',', 'Data', 'structures', ',', 'Agile', 'software', 'development', ',', 'DBMS', '.', 'CERTIFICATIONS', 'Java-in-depth', ',', 'Udemy', 'Software', 'development', 'agile', 'practices', ',', 'Coursera', '.', 'Python', 'for', 'Everybody', ',', 'Coursera', '.', 'CS50x', ',', 'Harvard', '.', 'React-the', 'complete', 'guide', ',', 'Udemy', '(', 'ongoing', ')', '.']\n",
            "[('SHRADDHA', 'O'), ('SURYAWANSHI', 'O'), ('shraddha3m', 'O'), ('@', 'O'), ('gmail.com', 'O'), ('8378032152', 'O'), ('Github', 'O'), ('LinkedIn', 'O'), ('SHRADDHA', 'O'), ('SURYAWANSHI', 'O'), ('shraddha3m', 'O'), ('@', 'O'), ('gmail.com', 'O'), ('8378032152', 'O'), ('Github', 'O'), ('LinkedIn', 'O'), ('EDUCATION', 'O'), ('SYMBIOSIS', 'O'), ('INSTITUTE', 'O'), ('OF', 'O'), ('TECHNOLOGY', 'O'), ('Pune', 'LOCATION'), (',', 'O'), ('MH', 'O'), (',', 'O'), ('IN', 'O'), ('B.TECH', 'O'), ('in', 'O'), ('Information', 'O'), ('Technology', 'O'), ('(', 'O'), ('CGPA', 'O'), (':', 'O'), ('8.36310.0', 'O'), (')', 'O'), ('2019-2023', 'O'), ('PROJECTS', 'O'), ('NGO', 'O'), ('EVENT', 'O'), ('MANAGEMENT', 'O'), ('WEBSITE', 'O'), (',', 'O'), ('April', 'O'), (',', 'O'), ('2020', 'O'), ('Co-developer', 'O'), ('A', 'O'), ('website', 'O'), ('where', 'O'), ('an', 'O'), ('NGO', 'O'), ('can', 'O'), ('better', 'O'), ('reach', 'O'), ('donors', 'O'), ('by', 'O'), ('advertising', 'O'), ('their', 'O'), ('clothesbooks', 'O'), ('donation', 'O'), ('drives', 'O'), ('.', 'O'), ('Makes', 'O'), ('it', 'O'), ('convenient', 'O'), ('for', 'O'), ('donors', 'O'), ('by', 'O'), ('allowing', 'O'), ('them', 'O'), ('to', 'O'), ('request', 'O'), ('door', 'O'), ('step', 'O'), ('pickup', 'O'), ('to', 'O'), ('the', 'O'), ('NGO', 'O'), ('.', 'O'), ('Uses', 'O'), ('JSP', 'ORGANIZATION'), (',', 'O'), ('Servlets', 'O'), (',', 'O'), ('MySQL', 'O'), (',', 'O'), ('HTML', 'O'), (',', 'O'), ('CSS', 'ORGANIZATION'), (',', 'O'), ('JS', 'O'), ('.', 'O'), ('DATA', 'O'), ('VISUALISATION', 'O'), ('WEBSITE', 'O'), ('Co-developer', 'O'), ('Ongoing', 'O'), ('October', 'O'), ('2021-', 'O'), ('Helps', 'O'), ('an', 'O'), ('NGO', 'O'), ('to', 'O'), ('view', 'O'), ('their', 'O'), ('kitchen', 'O'), ('operations', 'O'), ('(', 'O'), ('material', 'O'), ('used', 'O'), ('and', 'O'), ('bought', 'O'), ('per', 'O'), ('month', 'O'), (')', 'O'), ('efficiency', 'O'), ('visually', 'O'), ('in', 'O'), ('the', 'O'), ('form', 'O'), ('of', 'O'), ('simple', 'O'), ('charts', 'O'), ('.', 'O'), ('Can', 'O'), ('help', 'O'), ('analyse', 'O'), ('and', 'O'), ('adjust', 'O'), ('raw', 'O'), ('materials', 'O'), ('usage', 'O'), ('and', 'O'), ('thereby', 'O'), ('reduce', 'O'), ('wastage', 'O'), ('.', 'O'), ('Uses', 'O'), ('React', 'O'), (',', 'O'), ('Bootstrap', 'O'), (',', 'O'), ('node.js', 'O'), (',', 'O'), ('MySQL', 'O'), ('.', 'O'), ('ETCH-A-SKETCH', 'O'), ('Developer', 'O'), ('A', 'O'), ('sketch-pad', 'O'), ('like', 'O'), ('software', 'O'), ('of', 'O'), ('<', 'O'), ('=100', 'O'), ('*', 'O'), ('100', 'O'), ('grid', 'O'), ('to', 'O'), ('practice', 'O'), ('DOM', 'O'), ('manipulation', 'O'), ('using', 'O'), ('JavaScript', 'O'), ('.', 'O'), ('Grid', 'O'), ('cells', 'O'), ('change', 'O'), ('to', 'O'), ('desired', 'O'), ('colour', 'O'), ('when', 'O'), ('hovered', 'O'), ('over', 'O'), ('them', 'O'), ('.', 'O'), ('Uses', 'O'), ('JavaScript', 'O'), (',', 'O'), ('HTML', 'O'), (',', 'O'), ('CSS', 'ORGANIZATION'), ('.', 'O'), ('SKILLS', 'O'), ('AND', 'O'), ('RELEVANT', 'O'), ('COURSEWORK', 'O'), ('Java', 'O'), (',', 'O'), ('JSP', 'ORGANIZATION'), (',', 'O'), ('Servlets', 'O'), (',', 'O'), ('MySQL', 'O'), (',', 'O'), ('Python', 'PERSON'), (',', 'O'), ('C++', 'O'), (',', 'O'), ('HTML', 'O'), (',', 'O'), ('CSS', 'ORGANIZATION'), (',', 'O'), ('JS', 'O'), (',', 'O'), ('React', 'O'), ('.', 'O'), ('OS', 'O'), (',', 'O'), ('Networking', 'O'), (',', 'O'), ('Data', 'O'), ('structures', 'O'), (',', 'O'), ('Agile', 'O'), ('software', 'O'), ('development', 'O'), (',', 'O'), ('DBMS', 'O'), ('.', 'O'), ('CERTIFICATIONS', 'O'), ('Java-in-depth', 'O'), (',', 'O'), ('Udemy', 'ORGANIZATION'), ('Software', 'ORGANIZATION'), ('development', 'O'), ('agile', 'O'), ('practices', 'O'), (',', 'O'), ('Coursera', 'O'), ('.', 'O'), ('Python', 'PERSON'), ('for', 'O'), ('Everybody', 'O'), (',', 'O'), ('Coursera', 'PERSON'), ('.', 'O'), ('CS50x', 'O'), (',', 'O'), ('Harvard', 'ORGANIZATION'), ('.', 'O'), ('React-the', 'O'), ('complete', 'O'), ('guide', 'O'), (',', 'O'), ('Udemy', 'O'), ('(', 'O'), ('ongoing', 'O'), (')', 'O'), ('.', 'O')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting phone number"
      ],
      "metadata": {
        "id": "4vINFYF_MA_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import subprocess  \n",
        " \n",
        "def extract_mobile_number(resume_text):\n",
        "    phone = re.findall(re.compile(r'(?:(?:\\+?([1-9]|[0-9][0-9]|[0-9][0-9][0-9])\\s*(?:[.-]\\s*)?)?(?:\\(\\s*([2-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9])\\s*\\)|([0-9][1-9]|[0-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9]))\\s*(?:[.-]\\s*)?)?([2-9]1[02-9]|[2-9][02-9]1|[2-9][02-9]{2})\\s*(?:[.-]\\s*)?([0-9]{4})(?:\\s*(?:#|x\\.?|ext\\.?|extension)\\s*(\\d+))?'), resume_text)\n",
        "    \n",
        "    if phone:\n",
        "        number = ''.join(phone[0])\n",
        "        if len(number) > 10:\n",
        "            return number\n",
        "        else:\n",
        "            return number\n",
        "\n",
        "print(extract_mobile_number(txt))"
      ],
      "metadata": {
        "id": "6lGMwb0ONuhJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a919f06-c54f-417b-d1e6-1ff6364e1ff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8378032152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting email ids"
      ],
      "metadata": {
        "id": "IRm6CG3nME-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        " \n",
        "from pdfminer.high_level import extract_text\n",
        " \n",
        "EMAIL_REG = re.compile(r'[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+')\n",
        " \n",
        "def extract_emails(resume_text):\n",
        "    return re.findall(EMAIL_REG, resume_text)\n",
        "\n",
        "extract_emails(txt)"
      ],
      "metadata": {
        "id": "4CnBgF0MPi4-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b53ac25-be6e-46bc-f66c-588ce88d697e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['shraddha3m@gmail.com', 'shraddha3m@gmail.com']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests"
      ],
      "metadata": {
        "id": "M-NoN-OTRYtb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51f213a8-e0ef-43f0-cc4b-9d8a66fd4ff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting skills using skills.api"
      ],
      "metadata": {
        "id": "A-sJgou6MIq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import requests\n",
        " \n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "FGnLw4iBP-I2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "614826fb-e932-485e-8c27-088dc253aa59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def skill_exists(skill):\n",
        "    url = f'https://api.apilayer.com/skills?q={skill}'\n",
        "    headers = {'apikey': 'xCUHMojA9jzAm3TfY6OHAsCdVNLEx3UV'}\n",
        "    response = requests.request('GET', url, headers=headers)\n",
        "    result = response.json()\n",
        " \n",
        "    if response.status_code == 200:\n",
        "        return len(result) != 0 and result[0].lower() == skill.lower()\n",
        "    raise Exception(result.get('message'))"
      ],
      "metadata": {
        "id": "GBrsZEFgSl2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def extract_skills(input_text):\n",
        "    stop_words = stopwords.words('english')\n",
        "    word_tokens = word_tokenize(input_text)\n",
        " \n",
        "    # remove the stop words\n",
        "    filtered_tokens = [word for word in word_tokens if word not in stop_words]\n",
        " \n",
        "    # remove the punctuation\n",
        "    filtered_tokens = [word for word in filtered_tokens if word.isalpha()]\n",
        " \n",
        "    # generate bigrams and trigrams (such as artificial intelligence)\n",
        "    bigrams_trigrams = list(map(' '.join, nltk.everygrams(filtered_tokens, 2, 3)))\n",
        "    \n",
        "    print(bigrams_trigrams)\n",
        " \n",
        "    # we create a set to keep the results \n",
        "    found_skills = set()\n",
        " \n",
        "    # we search for each token in our skills database\n",
        "    for token in filtered_tokens:\n",
        "        if skill_exists(token.lower()):\n",
        "            found_skills.add(token)\n",
        " \n",
        "    # we search for each bigram and trigram in our skills database\n",
        "    for ngram in bigrams_trigrams:\n",
        "        if skill_exists(ngram.lower()):\n",
        "            found_skills.add(ngram)\n",
        " \n",
        "    return found_skills\n",
        "\n",
        "extract_skills(txt)"
      ],
      "metadata": {
        "id": "h-z217JeSZOU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfe9f057-aa1f-4ac9-89ce-b2611389646d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['SHRADDHA SURYAWANSHI', 'SHRADDHA SURYAWANSHI Github', 'SURYAWANSHI Github', 'SURYAWANSHI Github LinkedIn', 'Github LinkedIn', 'Github LinkedIn SHRADDHA', 'LinkedIn SHRADDHA', 'LinkedIn SHRADDHA SURYAWANSHI', 'SHRADDHA SURYAWANSHI', 'SHRADDHA SURYAWANSHI Github', 'SURYAWANSHI Github', 'SURYAWANSHI Github LinkedIn', 'Github LinkedIn', 'Github LinkedIn EDUCATION', 'LinkedIn EDUCATION', 'LinkedIn EDUCATION SYMBIOSIS', 'EDUCATION SYMBIOSIS', 'EDUCATION SYMBIOSIS INSTITUTE', 'SYMBIOSIS INSTITUTE', 'SYMBIOSIS INSTITUTE OF', 'INSTITUTE OF', 'INSTITUTE OF TECHNOLOGY', 'OF TECHNOLOGY', 'OF TECHNOLOGY Pune', 'TECHNOLOGY Pune', 'TECHNOLOGY Pune MH', 'Pune MH', 'Pune MH IN', 'MH IN', 'MH IN Information', 'IN Information', 'IN Information Technology', 'Information Technology', 'Information Technology CGPA', 'Technology CGPA', 'Technology CGPA PROJECTS', 'CGPA PROJECTS', 'CGPA PROJECTS NGO', 'PROJECTS NGO', 'PROJECTS NGO EVENT', 'NGO EVENT', 'NGO EVENT MANAGEMENT', 'EVENT MANAGEMENT', 'EVENT MANAGEMENT WEBSITE', 'MANAGEMENT WEBSITE', 'MANAGEMENT WEBSITE April', 'WEBSITE April', 'WEBSITE April A', 'April A', 'April A website', 'A website', 'A website NGO', 'website NGO', 'website NGO better', 'NGO better', 'NGO better reach', 'better reach', 'better reach donors', 'reach donors', 'reach donors advertising', 'donors advertising', 'donors advertising donation', 'advertising donation', 'advertising donation drives', 'donation drives', 'donation drives Makes', 'drives Makes', 'drives Makes convenient', 'Makes convenient', 'Makes convenient donors', 'convenient donors', 'convenient donors allowing', 'donors allowing', 'donors allowing request', 'allowing request', 'allowing request door', 'request door', 'request door step', 'door step', 'door step pickup', 'step pickup', 'step pickup NGO', 'pickup NGO', 'pickup NGO Uses', 'NGO Uses', 'NGO Uses JSP', 'Uses JSP', 'Uses JSP Servlets', 'JSP Servlets', 'JSP Servlets MySQL', 'Servlets MySQL', 'Servlets MySQL HTML', 'MySQL HTML', 'MySQL HTML CSS', 'HTML CSS', 'HTML CSS JS', 'CSS JS', 'CSS JS DATA', 'JS DATA', 'JS DATA VISUALISATION', 'DATA VISUALISATION', 'DATA VISUALISATION WEBSITE', 'VISUALISATION WEBSITE', 'VISUALISATION WEBSITE Ongoing', 'WEBSITE Ongoing', 'WEBSITE Ongoing October', 'Ongoing October', 'Ongoing October Helps', 'October Helps', 'October Helps NGO', 'Helps NGO', 'Helps NGO view', 'NGO view', 'NGO view kitchen', 'view kitchen', 'view kitchen operations', 'kitchen operations', 'kitchen operations material', 'operations material', 'operations material used', 'material used', 'material used bought', 'used bought', 'used bought per', 'bought per', 'bought per month', 'per month', 'per month efficiency', 'month efficiency', 'month efficiency visually', 'efficiency visually', 'efficiency visually form', 'visually form', 'visually form simple', 'form simple', 'form simple charts', 'simple charts', 'simple charts Can', 'charts Can', 'charts Can help', 'Can help', 'Can help analyse', 'help analyse', 'help analyse adjust', 'analyse adjust', 'analyse adjust raw', 'adjust raw', 'adjust raw materials', 'raw materials', 'raw materials usage', 'materials usage', 'materials usage thereby', 'usage thereby', 'usage thereby reduce', 'thereby reduce', 'thereby reduce wastage', 'reduce wastage', 'reduce wastage Uses', 'wastage Uses', 'wastage Uses React', 'Uses React', 'Uses React Bootstrap', 'React Bootstrap', 'React Bootstrap MySQL', 'Bootstrap MySQL', 'Bootstrap MySQL Developer', 'MySQL Developer', 'MySQL Developer A', 'Developer A', 'Developer A like', 'A like', 'A like software', 'like software', 'like software grid', 'software grid', 'software grid practice', 'grid practice', 'grid practice DOM', 'practice DOM', 'practice DOM manipulation', 'DOM manipulation', 'DOM manipulation using', 'manipulation using', 'manipulation using JavaScript', 'using JavaScript', 'using JavaScript Grid', 'JavaScript Grid', 'JavaScript Grid cells', 'Grid cells', 'Grid cells change', 'cells change', 'cells change desired', 'change desired', 'change desired colour', 'desired colour', 'desired colour hovered', 'colour hovered', 'colour hovered Uses', 'hovered Uses', 'hovered Uses JavaScript', 'Uses JavaScript', 'Uses JavaScript HTML', 'JavaScript HTML', 'JavaScript HTML CSS', 'HTML CSS', 'HTML CSS SKILLS', 'CSS SKILLS', 'CSS SKILLS AND', 'SKILLS AND', 'SKILLS AND RELEVANT', 'AND RELEVANT', 'AND RELEVANT COURSEWORK', 'RELEVANT COURSEWORK', 'RELEVANT COURSEWORK Java', 'COURSEWORK Java', 'COURSEWORK Java JSP', 'Java JSP', 'Java JSP Servlets', 'JSP Servlets', 'JSP Servlets MySQL', 'Servlets MySQL', 'Servlets MySQL Python', 'MySQL Python', 'MySQL Python HTML', 'Python HTML', 'Python HTML CSS', 'HTML CSS', 'HTML CSS JS', 'CSS JS', 'CSS JS React', 'JS React', 'JS React OS', 'React OS', 'React OS Networking', 'OS Networking', 'OS Networking Data', 'Networking Data', 'Networking Data structures', 'Data structures', 'Data structures Agile', 'structures Agile', 'structures Agile software', 'Agile software', 'Agile software development', 'software development', 'software development DBMS', 'development DBMS', 'development DBMS CERTIFICATIONS', 'DBMS CERTIFICATIONS', 'DBMS CERTIFICATIONS Udemy', 'CERTIFICATIONS Udemy', 'CERTIFICATIONS Udemy Software', 'Udemy Software', 'Udemy Software development', 'Software development', 'Software development agile', 'development agile', 'development agile practices', 'agile practices', 'agile practices Coursera', 'practices Coursera', 'practices Coursera Python', 'Coursera Python', 'Coursera Python Everybody', 'Python Everybody', 'Python Everybody Coursera', 'Everybody Coursera', 'Everybody Coursera Harvard', 'Coursera Harvard', 'Coursera Harvard complete', 'Harvard complete', 'Harvard complete guide', 'complete guide', 'complete guide Udemy', 'guide Udemy', 'guide Udemy ongoing', 'Udemy ongoing']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Agile',\n",
              " 'Bootstrap',\n",
              " 'CSS',\n",
              " 'Can',\n",
              " 'Coursera',\n",
              " 'DATA',\n",
              " 'Data',\n",
              " 'Data structures',\n",
              " 'EDUCATION',\n",
              " 'EVENT MANAGEMENT',\n",
              " 'Github',\n",
              " 'HTML',\n",
              " 'Information Technology',\n",
              " 'Java',\n",
              " 'JavaScript',\n",
              " 'LinkedIn',\n",
              " 'MANAGEMENT',\n",
              " 'MySQL',\n",
              " 'NGO',\n",
              " 'Networking',\n",
              " 'OS',\n",
              " 'PROJECTS',\n",
              " 'Python',\n",
              " 'SKILLS',\n",
              " 'Servlets',\n",
              " 'Software',\n",
              " 'Software development',\n",
              " 'TECHNOLOGY',\n",
              " 'Technology',\n",
              " 'Udemy',\n",
              " 'VISUALISATION',\n",
              " 'WEBSITE',\n",
              " 'advertising',\n",
              " 'agile',\n",
              " 'cells',\n",
              " 'development',\n",
              " 'donors',\n",
              " 'drives',\n",
              " 'form',\n",
              " 'materials',\n",
              " 'operations',\n",
              " 'raw materials',\n",
              " 'reach',\n",
              " 'software',\n",
              " 'software development',\n",
              " 'step',\n",
              " 'structures',\n",
              " 'website'}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OUTPUT FOR SKILLS\n",
        "\n",
        "# ['SHRADDHA SURYAWANSHI', 'SHRADDHA SURYAWANSHI Github', 'SURYAWANSHI Github', 'SURYAWANSHI Github LinkedIn', 'Github LinkedIn', 'Github LinkedIn EDUCATION', 'LinkedIn EDUCATION', 'LinkedIn EDUCATION SYMBIOSIS', 'EDUCATION SYMBIOSIS', 'EDUCATION SYMBIOSIS INSTITUTE', 'SYMBIOSIS INSTITUTE', 'SYMBIOSIS INSTITUTE OF', 'INSTITUTE OF', 'INSTITUTE OF TECHNOLOGY', 'OF TECHNOLOGY', 'OF TECHNOLOGY Information', 'TECHNOLOGY Information', 'TECHNOLOGY Information Technology', 'Information Technology', 'Information Technology CGPA', 'Technology CGPA', 'Technology CGPA PROJECTS', 'CGPA PROJECTS', 'CGPA PROJECTS NGO', 'PROJECTS NGO', 'PROJECTS NGO EVENT', 'NGO EVENT', 'NGO EVENT MANAGEMENT', 'EVENT MANAGEMENT', 'EVENT MANAGEMENT WEBSITE', 'MANAGEMENT WEBSITE', 'MANAGEMENT WEBSITE Pune', 'WEBSITE Pune', 'WEBSITE Pune MH', 'Pune MH', 'Pune MH IN', 'MH IN', 'MH IN April', 'IN April', 'IN April A', 'April A', 'April A website', 'A website', 'A website NGO', 'website NGO', 'website NGO better', 'NGO better', 'NGO better reach', 'better reach', 'better reach donors', 'reach donors', 'reach donors advertising', 'donors advertising', 'donors advertising donation', 'advertising donation', 'advertising donation drives', 'donation drives', 'donation drives Makes', 'drives Makes', 'drives Makes convenient', 'Makes convenient', 'Makes convenient donors', 'convenient donors', 'convenient donors allowing', 'donors allowing', 'donors allowing request', 'allowing request', 'allowing request door', 'request door', 'request door step', 'door step', 'door step pickup', 'step pickup', 'step pickup NGO', 'pickup NGO', 'pickup NGO Uses', 'NGO Uses', 'NGO Uses JSP', 'Uses JSP', 'Uses JSP Servlets', 'JSP Servlets', 'JSP Servlets MySQL', 'Servlets MySQL', 'Servlets MySQL HTML', 'MySQL HTML', 'MySQL HTML CSS', 'HTML CSS', 'HTML CSS JS', 'CSS JS', 'CSS JS DATA', 'JS DATA', 'JS DATA VISUALISATION', 'DATA VISUALISATION', 'DATA VISUALISATION WEBSITE', 'VISUALISATION WEBSITE', 'VISUALISATION WEBSITE Ongoing', 'WEBSITE Ongoing', 'WEBSITE Ongoing October', 'Ongoing October', 'Ongoing October Helps', 'October Helps', 'October Helps NGO', 'Helps NGO', 'Helps NGO view', 'NGO view', 'NGO view kitchen', 'view kitchen', 'view kitchen operations', 'kitchen operations', 'kitchen operations material', 'operations material', 'operations material used', 'material used', 'material used bought', 'used bought', 'used bought per', 'bought per', 'bought per month', 'per month', 'per month efficiency', 'month efficiency', 'month efficiency visually', 'efficiency visually', 'efficiency visually form', 'visually form', 'visually form simple', 'form simple', 'form simple charts', 'simple charts', 'simple charts Can', 'charts Can', 'charts Can help', 'Can help', 'Can help analyse', 'help analyse', 'help analyse adjust', 'analyse adjust', 'analyse adjust raw', 'adjust raw', 'adjust raw materials', 'raw materials', 'raw materials usage', 'materials usage', 'materials usage thereby', 'usage thereby', 'usage thereby reduce', 'thereby reduce', 'thereby reduce wastage', 'reduce wastage', 'reduce wastage Uses', 'wastage Uses', 'wastage Uses React', 'Uses React', 'Uses React Bootstrap', 'React Bootstrap', 'React Bootstrap MySQL', 'Bootstrap MySQL', 'Bootstrap MySQL Developer', 'MySQL Developer', 'MySQL Developer A', 'Developer A', 'Developer A like', 'A like', 'A like software', 'like software', 'like software grid', 'software grid', 'software grid practice', 'grid practice', 'grid practice DOM', 'practice DOM', 'practice DOM manipulation', 'DOM manipulation', 'DOM manipulation using', 'manipulation using', 'manipulation using JavaScript', 'using JavaScript', 'using JavaScript Grid', 'JavaScript Grid', 'JavaScript Grid cells', 'Grid cells', 'Grid cells change', 'cells change', 'cells change desired', 'change desired', 'change desired colour', 'desired colour', 'desired colour hovered', 'colour hovered', 'colour hovered Uses', 'hovered Uses', 'hovered Uses JavaScript', 'Uses JavaScript', 'Uses JavaScript HTML', 'JavaScript HTML', 'JavaScript HTML CSS', 'HTML CSS', 'HTML CSS SKILLS', 'CSS SKILLS', 'CSS SKILLS AND', 'SKILLS AND', 'SKILLS AND RELEVANT', 'AND RELEVANT', 'AND RELEVANT COURSEWORK', 'RELEVANT COURSEWORK', 'RELEVANT COURSEWORK Java', 'COURSEWORK Java', 'COURSEWORK Java JSP', 'Java JSP', 'Java JSP Servlets', 'JSP Servlets', 'JSP Servlets MySQL', 'Servlets MySQL', 'Servlets MySQL Python', 'MySQL Python', 'MySQL Python HTML', 'Python HTML', 'Python HTML CSS', 'HTML CSS', 'HTML CSS JS', 'CSS JS', 'CSS JS React', 'JS React', 'JS React OS', 'React OS', 'React OS Networking', 'OS Networking', 'OS Networking Data', 'Networking Data', 'Networking Data structures', 'Data structures', 'Data structures Agile', 'structures Agile', 'structures Agile software', 'Agile software', 'Agile software development', 'software development', 'software development DBMS', 'development DBMS', 'development DBMS CERTIFICATIONS', 'DBMS CERTIFICATIONS', 'DBMS CERTIFICATIONS Udemy', 'CERTIFICATIONS Udemy', 'CERTIFICATIONS Udemy Software', 'Udemy Software', 'Udemy Software development', 'Software development', 'Software development agile', 'development agile', 'development agile practices', 'agile practices', 'agile practices Coursera', 'practices Coursera', 'practices Coursera Python', 'Coursera Python', 'Coursera Python Everybody', 'Python Everybody', 'Python Everybody Coursera', 'Everybody Coursera', 'Everybody Coursera Harvard', 'Coursera Harvard', 'Coursera Harvard complete', 'Harvard complete', 'Harvard complete guide', 'complete guide', 'complete guide Udemy', 'guide Udemy', 'guide Udemy ongoing', 'Udemy ongoing']\n",
        "\n",
        "# {'Agile',\n",
        "#  'Bootstrap',\n",
        "#  'CSS',\n",
        "#  'Can',\n",
        "#  'Coursera',\n",
        "#  'DATA',\n",
        "#  'Data',\n",
        "#  'Data structures',\n",
        "#  'EDUCATION',\n",
        "#  'EVENT MANAGEMENT',\n",
        "#  'Github',\n",
        "#  'HTML',\n",
        "#  'Information Technology',\n",
        "#  'Java',\n",
        "#  'JavaScript',\n",
        "#  'LinkedIn',\n",
        "#  'MANAGEMENT',\n",
        "#  'MySQL',\n",
        "#  'NGO',\n",
        "#  'Networking',\n",
        "#  'OS',\n",
        "#  'PROJECTS',\n",
        "#  'Python',\n",
        "#  'SKILLS',\n",
        "#  'Servlets',\n",
        "#  'Software',\n",
        "#  'Software development',\n",
        "#  'TECHNOLOGY',\n",
        "#  'Technology',\n",
        "#  'Udemy',\n",
        "#  'VISUALISATION',\n",
        "#  'WEBSITE',\n",
        "#  'advertising',\n",
        "#  'agile',\n",
        "#  'cells',\n",
        "#  'development',\n",
        "#  'donors',\n",
        "#  'drives',\n",
        "#  'form',\n",
        "#  'materials',\n",
        "#  'operations',\n",
        "#  'raw materials',\n",
        "#  'reach',\n",
        "#  'software',\n",
        "#  'software development',\n",
        "#  'step',\n",
        "#  'structures',\n",
        "#  'website'}"
      ],
      "metadata": {
        "id": "Zmf3wctQtnhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting qualifications"
      ],
      "metadata": {
        "id": "VKasRRdKMZVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "Z-_uF_QqVM-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1720544c-c68c-4867-95aa-20d50951e52d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "# Grad all general stop words\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "# Education Degrees\n",
        "EDUCATION = [\n",
        "            'BE','B.E.', 'B.E', 'BS', 'B.S', \n",
        "            'ME', 'M.E', 'M.E.', 'M.B.A', 'MBA', 'MS', 'M.S', \n",
        "            'BTECH', 'B.TECH', 'M.TECH', 'MTECH', \n",
        "            'SSLC', 'SSC' 'HSC', 'CBSE', 'ICSE', 'X', 'XII'\n",
        "        ]\n",
        "\n",
        "def extract_education(resume_text):\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    nlp_text = nlp(resume_text)\n",
        "\n",
        "    # Sentence Tokenizer\n",
        "    nlp_text = [sent.text.strip() for sent in nlp_text.sents]\n",
        "\n",
        "    edu = {}\n",
        "    # Extract education degree\n",
        "    for index, text in enumerate(nlp_text):\n",
        "        for tex in text.split():\n",
        "            # Replace all special symbols\n",
        "            tex = re.sub(r'[?|$|.|!|,]', r'', tex)\n",
        "            if tex.upper() in EDUCATION and tex not in STOPWORDS:\n",
        "                edu[tex] = text + nlp_text[index + 1]\n",
        "                \n",
        "                \n",
        "\n",
        "    # Extract year\n",
        "    education = []\n",
        "    for key in edu.keys():\n",
        "        year = re.search(re.compile(r'(((20|19)(\\d{})))'), edu[key])\n",
        "        if year:\n",
        "            education.append((key, ''.join(year[0])))\n",
        "        else:\n",
        "            education.append(key)\n",
        "    return education\n",
        "print('Qualification: ',extract_education(txt))"
      ],
      "metadata": {
        "id": "tw-fgq96RTM3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9566599e-8a92-4eb5-ed16-e4fec193f3ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Qualification:  ['BTECH']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting universities"
      ],
      "metadata": {
        "id": "tOZuPqp3cfiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ZWPuq0z6asiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_university(text, file):\n",
        "        df = pd.read_csv(file, header=None)\n",
        "        universities = [i.lower() for i in df[1]]\n",
        "        college_name = []\n",
        "        listex = universities\n",
        "        listsearch = [text.lower()]\n",
        "\n",
        "        for i in range(len(listex)):\n",
        "            for ii in range(len(listsearch)):\n",
        "                \n",
        "                if re.findall(listex[i], re.sub(' +', ' ', listsearch[ii])):\n",
        "                \n",
        "                    college_name.append(listex[i])\n",
        "        \n",
        "        return college_name\n",
        "extract_university(txt, '/content/sample_data/world-universities.csv')"
      ],
      "metadata": {
        "id": "dK4NH-dxaQEJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "651cd8fa-b4f9-42d5-916d-a074edc70dfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ]
}